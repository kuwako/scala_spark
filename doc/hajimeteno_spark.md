# 初めてのSpark
## 3章 RDD
### 永続化
同じRDDを複数回使う場合、Sparkは依存対象を再計算してしまうのでpersist(), unpersist()でメモリ上に適切にキャッシュしておくことが大切  
unpersist()をし忘れるとメモリ上に保持され続け、後続の処理を圧迫してしまうので注意

## 4章 キー/値ペアの処理
### データのパーティショニング
前提: 分散プログラムでは、通信のコストが最も高いことが多い  
→ partitionBy()をうまく活用し、通信回数を減らす必要がある  

パーティショニングの恩恵を受けられるのは
- cogroup()
- join系
- groupByKey()
- reduceByKey()

などのキーを変更しない操作  
(= パーティショニングはキーを軸に行われるため)  

mapを使用すると、キーを維持して居るかsparkは判断できないため、パーティショナは崩れる  
- パーティショナを維持してmap処理をする場合はmapValues()やflatMapValue()のような、キーを維持していることを証明できるメソッドを利用する必要がある  
- カスタムパーティショナを自分で作れば、より効率の良いパーティションが実現できるが、パーティションごとにデータ量が偏ると全体に影響が出てしまうので注意が必要

## 6章 Sparkの高度なプログラミング
### アキュムレータ
- ワーカーノード群からドライバプログラムへ値を集約する
- 正しい値がわかるのは、saveAsTextFile等のアクションが行われてmap処理等が実行されたあとになる
- ワーカーノードからは書き込みオンリー
- アキュムレータの値はワーカーノードが途中でダウンした場合等に間違った値になりうるので、デバッグ用途で使われるべき

### ブロードキャスト変数
大きなリードオンリーの変数をワーカーに効率よく送る
- 一度ワーカーノードに送ったらそれ以降その変数を通信しないため

### 外部のプログラムへのパイプ
例えばpipe関数で既存のRプログラムに値を渡したりできる

## 7章 クラスタでの動作
有向非循環グラフ = DAG(Directed Acyclic Graph)  
実行グラフ → stage群に変換  
stage → タスク群  
に変換される  
  
※ Sparkのドキュメントでは、Sparkアプリケーションを実行するプロセスを説明する上ではドライバとエグゼキュータという名前を使い、クラスタマネージャを表現する際はマスターとワーカーという言葉が使われているが指してるものは同じ

## 8章 Sparkのチューニングとデバッグ
### 設定項目
- spark.speculation 
  - default:false
  - trueにすると
