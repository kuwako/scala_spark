# 初めてのSpark
## 3章 RDD
### 永続化
同じRDDを複数回使う場合、Sparkは依存対象を再計算してしまうのでpersist(), unpersist()でメモリ上に適切にキャッシュしておくことが大切  
unpersist()をし忘れるとメモリ上に保持され続け、後続の処理を圧迫してしまうので注意

## 4章 キー/値ペアの処理
### データのパーティショニング
前提: 分散プログラムでは、通信のコストが最も高いことが多い  
→ partitionBy()をうまく活用し、通信回数を減らす必要がある  

パーティショニングの恩恵を受けられるのは
- cogroup()
- join系
- groupByKey()
- reduceByKey()

などのキーを変更しない操作  
(= パーティショニングはキーを軸に行われるため)  

mapを使用すると、キーを維持して居るかsparkは判断できないため、パーティショナは崩れる  
- パーティショナを維持してmap処理をする場合はmapValues()やflatMapValue()のような、キーを維持していることを証明できるメソッドを利用する必要がある  
- カスタムパーティショナを自分で作れば、より効率の良いパーティションが実現できるが、パーティションごとにデータ量が偏ると全体に影響が出てしまうので注意が必要

## 6章 Sparkの高度なプログラミング
### アキュムレータ
- ワーカーノード群からドライバプログラムへ値を集約する
- 正しい値がわかるのは、saveAsTextFile等のアクションが行われてmap処理等が実行されたあとになる
- ワーカーノードからは書き込みオンリー
- アキュムレータの値はワーカーノードが途中でダウンした場合等に間違った値になりうるので、デバッグ用途で使われるべき

### ブロードキャスト変数
大きなリードオンリーの変数をワーカーに効率よく送る
- 一度ワーカーノードに送ったらそれ以降その変数を通信しないため

### 外部のプログラムへのパイプ
例えばpipe関数で既存のRプログラムに値を渡したりできる

## 7章 クラスタでの動作
有向非循環グラフ = DAG(Directed Acyclic Graph)  
実行グラフ → stage群に変換  
stage → タスク群  
に変換される  
  
※ Sparkのドキュメントでは、Sparkアプリケーションを実行するプロセスを説明する上ではドライバとエグゼキュータという名前を使い、クラスタマネージャを表現する際はマスターとワーカーという言葉が使われているが指してるものは同じ

## 8章 Sparkのチューニングとデバッグ
### 設定項目
- spark.speculation 
  - default:false
  - trueにすると実行速度の遅いタスクをコピーし、他のノードで走らせ始める

### その他
- 明示的に永続化しなくても、それ以前のシャッフルで副作用として実体化(ディスク書き込み)して居る場合、それが利用される

### WebUI
- スキューがパフォーマンスを低下させうる
  - 少数のタスクが他のタスクに比べて多くの時間を使って居る時に発生
  - スキューとは: CPUのクロックが複数の論理回線の経路を辿ることによって発生する、タイミングのずれ。CPU回路の伝送について配線容量や遅延時間の差などによって発生する。
- storageタブ
  - 各RDDのキャッシュされている箇所と容量がわかる
- Executorsタブ
  - デバッグ時は最初に見ると良い
  - 初学者はエグゼキュータのリソースの量を確認すべき

## パフォーマンスに関する重要な考慮点
### 並列度
- 多くのユースケースで1パーティションに1タスクを生成し、クラスタ内の1CPUで処理させるのは適切である
- 並列度のチューニング方法は2つ
    1. データのシャッフルの際にパラメータとして、生成されるRDDの並列度を指定
    1. 任意のRDDを再配分して、パーティション数を増減する
        - repartition(), coalesce()を使える
        - 例えば、filterで明らかにデータ量が減る場合、coalesceでパーティション数を減らすことで最適化できる
- シリアライゼーションのフォーマット
    - 大量のデータのシャッフルが行われる場合は効果が大きい
    - Kryoを利用すると更に効果が高い

### メモリ管理
- RDDのストレージ
    - persist()でバッファに保存
    - cacheに割り当てる割合は一定に制限されていて、spark.storage.memoryFunctionでチューニング可能
- シャッフルと集計のバッファ
    - シャッフル処理を行う際に出力を保存する中間バッファ
    - spark.shuffle.memoryFunctionでチューニング可能
- ユーザーコード
    - ソース中で大きな配列やオブジェクトなどがある場合は大きく活用される

#### そのほか
- デフォルトでは60%をRDD, 20%をシャッフル, 残りをユーザーコードに割り当てている  
- persistはデフォルトではMEMORY_ONLYだが、再計算のコストが大きい場合はMEMORY_AND_DISKでpersistした方が良い  
- 場合によってはJavaオブジェクトをシリアライズしてpersistするのが有効な場合がある
    - 大量のデータをキャッシュする場合、ガベコレによる処理中断がコストになっている場合は検討(各タスクのGCtimeを確認すること)

### ハードウェアのプロビジョニング
- メモリやCPUコアが多いほど有効
- エグゼキュータのためのメモリ指定に落とし穴がある
    - ヒープサイズを大きくするとガベコレによってsparkのジョブのスループットが損なわれるので、注意

## 9章SparkSQL
SparkSQL中から、Scala, Java, Pythonで書いたUDF(ユーザー定義関数)を呼べるのである意味柔軟なsqlがかける

### パフォーマンスチューニング
spark.sql.codegen: default false
- trueにすると、クエリ実行に先立ってJavaのバイトコードにコンパイルされるので、実行時間の長いクエリや何度も実行するクエリには有効
- 逆にコストの低いものであれば、コンパイルのオーバーヘッドの方が大きくなってしまう

## 11章 MLlib
MLlibに含まれて居るのは並列アルゴリズムのみ
